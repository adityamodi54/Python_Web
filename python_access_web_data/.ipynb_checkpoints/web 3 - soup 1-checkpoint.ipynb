{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nDone\\nWelcome Aditya Modi from Using Python to Access Web Data\\n\\nScraping Numbers from HTML using BeautifulSoup In this assignment you will write a Python program similar to http://www.py4e.com/code3/urllink2.py. The program will use urllib to read the HTML from the data files below, and parse the data, extracting numbers and compute the sum of the numbers in the file.\\n\\nWe provide two files for this assignment. One is a sample file where we give you the sum for your testing and the other is the actual data you need to process for the assignment.\\n\\nSample data: http://py4e-data.dr-chuck.net/comments_42.html (Sum=2553)\\nActual data: http://py4e-data.dr-chuck.net/comments_113065.html (Sum ends with 17)\\nYou do not need to save these files to your folder since your program will read the data directly from the URL. Note: Each student will have a distinct data url for the assignment - so only use your own data url for analysis.\\nData Format\\nThe file is a table of names and comment counts. You can ignore most of the data in the file except for lines like the following:\\n\\n<tr><td>Modu</td><td><span class=\"comments\">90</span></td></tr>\\n<tr><td>Kenzie</td><td><span class=\"comments\">88</span></td></tr>\\n<tr><td>Hubert</td><td><span class=\"comments\">87</span></td></tr>\\nYou are to find all the <span> tags in the file and pull out the numbers from the tag and sum the numbers.\\nLook at the sample code provided. It shows how to find all of a certain kind of tag, loop through the tags and extract the various aspects of the tags.\\n\\n...\\n# Retrieve all of the anchor tags\\ntags = soup(\\'a\\')\\nfor tag in tags:\\n   # Look at the parts of a tag\\n   print \\'TAG:\\',tag\\n   print \\'URL:\\',tag.get(\\'href\\', None)\\n   print \\'Contents:\\',tag.contents[0]\\n   print \\'Attrs:\\',tag.attrs\\nYou need to adjust this code to look for span tags and pull out the text content of the span tag, convert them to integers and add them up to complete the assignment.\\nSample Execution\\n\\n$ python3 solution.py\\nEnter - http://py4e-data.dr-chuck.net/comments_42.html\\nCount 50\\nSum 2...\\nTurning in the Assignment\\n\\nEnter the sum from the actual data and your Python code below:\\nSum: \\n (ends with 17) \\nPython code:\\n\\nSelect Language\\u200b▼\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Done\n",
    "Welcome Aditya Modi from Using Python to Access Web Data\n",
    "\n",
    "Scraping Numbers from HTML using BeautifulSoup In this assignment you will write a Python program similar to http://www.py4e.com/code3/urllink2.py. The program will use urllib to read the HTML from the data files below, and parse the data, extracting numbers and compute the sum of the numbers in the file.\n",
    "\n",
    "We provide two files for this assignment. One is a sample file where we give you the sum for your testing and the other is the actual data you need to process for the assignment.\n",
    "\n",
    "Sample data: http://py4e-data.dr-chuck.net/comments_42.html (Sum=2553)\n",
    "Actual data: http://py4e-data.dr-chuck.net/comments_113065.html (Sum ends with 17)\n",
    "You do not need to save these files to your folder since your program will read the data directly from the URL. Note: Each student will have a distinct data url for the assignment - so only use your own data url for analysis.\n",
    "Data Format\n",
    "The file is a table of names and comment counts. You can ignore most of the data in the file except for lines like the following:\n",
    "\n",
    "<tr><td>Modu</td><td><span class=\"comments\">90</span></td></tr>\n",
    "<tr><td>Kenzie</td><td><span class=\"comments\">88</span></td></tr>\n",
    "<tr><td>Hubert</td><td><span class=\"comments\">87</span></td></tr>\n",
    "You are to find all the <span> tags in the file and pull out the numbers from the tag and sum the numbers.\n",
    "Look at the sample code provided. It shows how to find all of a certain kind of tag, loop through the tags and extract the various aspects of the tags.\n",
    "\n",
    "...\n",
    "# Retrieve all of the anchor tags\n",
    "tags = soup('a')\n",
    "for tag in tags:\n",
    "   # Look at the parts of a tag\n",
    "   print 'TAG:',tag\n",
    "   print 'URL:',tag.get('href', None)\n",
    "   print 'Contents:',tag.contents[0]\n",
    "   print 'Attrs:',tag.attrs\n",
    "You need to adjust this code to look for span tags and pull out the text content of the span tag, convert them to integers and add them up to complete the assignment.\n",
    "Sample Execution\n",
    "\n",
    "$ python3 solution.py\n",
    "Enter - http://py4e-data.dr-chuck.net/comments_42.html\n",
    "Count 50\n",
    "Sum 2...\n",
    "Turning in the Assignment\n",
    "\n",
    "Enter the sum from the actual data and your Python code below:\n",
    "Sum: \n",
    " (ends with 17) \n",
    "Python code:\n",
    "\n",
    "Select Language​▼\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Steps to solve this\n",
    "\n",
    "understand how it works\n",
    "how can tags be scrapped\n",
    "how to scrape all numbers\n",
    "\n",
    "how will u add them\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'int' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-916fa58c171a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mnumbers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspan\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstring\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnumbers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;31m# https://github.com/richyvk/python-web-data/blob/master/Week-4/bs4-scraper.py\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'int' object is not callable"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "page = urllib.request.urlopen('http://py4e-data.dr-chuck.net/comments_42.html')\n",
    "soup = BeautifulSoup(page, \"html.parser\")\n",
    "\n",
    "spans = soup('span')\n",
    "\n",
    "numbers = []\n",
    "\n",
    "for span in spans:\n",
    "    numbers.append(int(span.string))\n",
    "\n",
    "print (sum(numbers))\n",
    "\n",
    "# https://github.com/richyvk/python-web-data/blob/master/Week-4/bs4-scraper.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum  2817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aditya Modi\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 193 of the file C:\\Users\\Aditya Modi\\Anaconda3\\lib\\runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP})\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP, \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = (\"http://py4e-data.dr-chuck.net/comments_113065.html\")\n",
    "\n",
    "html = urllib.request.urlopen(url).read()\n",
    "soup = BeautifulSoup(html)\n",
    "\n",
    "spantags = soup('span')\n",
    "\n",
    "sum1 = 0\n",
    "\n",
    "for tag in spantags:\n",
    "    #print tag\n",
    "    #print tag.contents[0]\n",
    "    sum1 = sum1 + int(tag.contents[0])\n",
    "    # print ta1g.attrs\n",
    "\n",
    "print (\"Sum \",sum1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Welcome to the comments assignment from www.py4e.com'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    " \n",
    "req = requests.get('http://py4e-data.dr-chuck.net/comments_42.html')\n",
    "soup = BeautifulSoup(req.text, \"lxml\")\n",
    " \n",
    "soup.title.string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[97, 97, 90, 90, 88, 87, 87, 80, 79, 79, 78, 76, 76, 72, 72, 66, 66, 65, 65, 64, 61, 61, 59, 58, 57, 57, 54, 51, 49, 47, 40, 38, 37, 36, 36, 32, 25, 24, 22, 21, 19, 18, 18, 14, 12, 12, 9, 7, 3, 2]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'int' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-174953968f8d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtag\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: 'int' object is not callable"
     ]
    }
   ],
   "source": [
    "array = []\n",
    "for tag in soup.find_all(\"span\"):\n",
    "#         print(tag.text)\n",
    "        array.append(int(tag.text))    \n",
    "print(array)\n",
    "print(sum(array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'int' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-44-7c347609430f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mnew\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtag\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstring\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: 'int' object is not callable"
     ]
    }
   ],
   "source": [
    "new=[]\n",
    "for tag in soup.find_all(\"span\"):\n",
    "    new.append(int(tag.string))\n",
    "\n",
    "print(sum(new))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
